{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alanland/colab-notebooks/blob/main/localGPT/localGPT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hg8LXAe8mt-G"
      },
      "source": [
        "## localGPT\n",
        "\n",
        "https://github.com/PromtEngineer/localGPT\n",
        "\n",
        "\n",
        "More details can be founded in [![GitHub](https://img.shields.io/github/stars/imartinez/privateGPT?style=social)](https://github.com/imartinez/privateGPT/)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ijIJmBFLebe3",
        "outputId": "2a4a5780-12af-4397-b96a-6b161f10e667",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tesla T4, 15360 MiB, 15101 MiB\n"
          ]
        }
      ],
      "source": [
        "### make sure that CUDA is available in Edit -> Nootbook settings -> GPU\n",
        "!nvidia-smi --query-gpu=name,memory.total,memory.free --format=csv,noheader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jn_LkaeUmFJQ"
      },
      "source": [
        "## Installnation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "_y8F_z_-hd9w",
        "outputId": "71fe3e02-e643-4112-f207-517b6ed87a5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "Error: Failed to call git rev-parse --git-dir: exit status 128 \n",
            "Git LFS initialized.\n",
            "Cloning into 'localGPT'...\n",
            "remote: Enumerating objects: 153, done.\u001b[K\n",
            "remote: Counting objects: 100% (57/57), done.\u001b[K\n",
            "remote: Compressing objects: 100% (35/35), done.\u001b[K\n",
            "remote: Total 153 (delta 40), reused 34 (delta 22), pack-reused 96\u001b[K\n",
            "Receiving objects: 100% (153/153), 454.71 KiB | 1.93 MiB/s, done.\n",
            "Resolving deltas: 100% (80/80), done.\n",
            "/content/localGPT\n"
          ]
        }
      ],
      "source": [
        "#@title git clone\n",
        "%cd /content\n",
        "!git lfs install\n",
        "!git clone https://github.com/alanland/localGPT.git\n",
        "%cd localGPT"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title checkout\n",
        "!git checkout main-local\n",
        "!git pull"
      ],
      "metadata": {
        "id": "7udHDXrw4Aq1",
        "outputId": "d75339ad-ef3d-4a9d-a920-6998bcefcf48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Branch 'main-local' set up to track remote branch 'main-local' from 'origin'.\n",
            "Switched to a new branch 'main-local'\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title install dependencies\n",
        "\n",
        "# Install dependencies\n",
        "%cd /content/localGPT\n",
        "!pip install -r requirements.txt\n",
        "\n",
        "#%cd /content\n",
        "#!rm -rf langchain\n",
        "#!rm -rf llama-cpp-python\n",
        "#!git clone https://github.com/hwchase17/langchain\n",
        "#!git clone https://github.com/abetlen/llama-cpp-python\n",
        "#%cd llama-cpp-python/vendor\n",
        "#!git clone https://github.com/ggerganov/llama.cpp\n",
        "\n",
        "#%cd /content\n",
        "\n",
        "#!pip3 uninstall llama-cpp-python -y\n",
        "#!pip3 install scikit-build\n",
        "#%cd /content/llama-cpp-python\n",
        "#!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" FORCE_CMAKE=1 python3 ./setup.py install\n",
        "\n",
        "#%cd /content/langchain\n",
        "#!pip3 uninstall langchain -y\n",
        "#!pip3 install -e ."
      ],
      "metadata": {
        "id": "yDxaRuBP4KoO",
        "outputId": "de7c011a-acee-4030-cae8-8ea12923412a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting linkify-it-py<3,>=1 (from markdown-it-py[linkify]>=2.0.0->gradio==3.33.1->-r requirements.txt (line 16))\n",
            "  Downloading linkify_it_py-2.0.2-py3-none-any.whl (19 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.3->chromadb==0.3.22->-r requirements.txt (line 2)) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb==0.3.22->-r requirements.txt (line 2)) (1.16.0)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb==0.3.22->-r requirements.txt (line 2)) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb==0.3.22->-r requirements.txt (line 2)) (2.2.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain==0.0.166->-r requirements.txt (line 1)) (3.4)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain==0.0.166->-r requirements.txt (line 1)) (2.0.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers->-r requirements.txt (line 7)) (1.11.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers->-r requirements.txt (line 7)) (3.1)\n",
            "Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6.0->sentence-transformers->-r requirements.txt (line 7)) (2.0.0)\n",
            "Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers->-r requirements.txt (line 7)) (3.25.2)\n",
            "Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.6.0->sentence-transformers->-r requirements.txt (line 7)) (16.0.5)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.22->-r requirements.txt (line 2)) (0.14.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.22->-r requirements.txt (line 2)) (0.5.0)\n",
            "Requirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.22->-r requirements.txt (line 2)) (1.0.0)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.22->-r requirements.txt (line 2)) (0.17.0)\n",
            "Requirement already satisfied: watchfiles>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb==0.3.22->-r requirements.txt (line 2)) (0.19.0)\n",
            "Requirement already satisfied: httpcore<0.17.0,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.33.1->-r requirements.txt (line 16)) (0.16.3)\n",
            "Requirement already satisfied: rfc3986[idna2008]<2,>=1.3 in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.33.1->-r requirements.txt (line 16)) (1.5.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx->gradio==3.33.1->-r requirements.txt (line 16)) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio==3.33.1->-r requirements.txt (line 16)) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio==3.33.1->-r requirements.txt (line 16)) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio==3.33.1->-r requirements.txt (line 16)) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio==3.33.1->-r requirements.txt (line 16)) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->gradio==3.33.1->-r requirements.txt (line 16)) (3.0.9)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->sentence-transformers->-r requirements.txt (line 7)) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence-transformers->-r requirements.txt (line 7)) (3.1.0)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20221105->-r requirements.txt (line 5)) (2.21)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from httpcore<0.17.0,>=0.15.0->httpx->gradio==3.33.1->-r requirements.txt (line 16)) (3.6.2)\n",
            "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair>=4.2.0->gradio==3.33.1->-r requirements.txt (line 16)) (0.19.3)\n",
            "Collecting uc-micro-py (from linkify-it-py<3,>=1->markdown-it-py[linkify]>=2.0.0->gradio==3.33.1->-r requirements.txt (line 16))\n",
            "  Downloading uc_micro_py-1.0.2-py3-none-any.whl (6.2 kB)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain==0.0.166->-r requirements.txt (line 1)) (1.0.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6.0->sentence-transformers->-r requirements.txt (line 7)) (1.3.0)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.0-py3-none-any.whl size=4694 sha256=bf740f9f8db2934af1c7eb25b1067d06041ae2a34350c1864cd172380e6e1227\n",
            "  Stored in directory: /root/.cache/pip/wheels/0c/c2/0e/3b9c6845c6a4e35beb90910cc70d9ac9ab5d47402bd62af0df\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, uc-micro-py, semantic-version, python-multipart, orjson, aiofiles, mdit-py-plugins, linkify-it-py, gradio-client, gradio\n",
            "Successfully installed aiofiles-23.1.0 ffmpy-0.3.0 gradio-3.33.1 gradio-client-0.2.5 linkify-it-py-2.0.2 mdit-py-plugins-0.3.3 orjson-3.9.0 pydub-0.25.1 python-multipart-0.0.6 semantic-version-2.10.0 uc-micro-py-1.0.2\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Install Koala 7B GGML Q4\n",
        "!mkdir /content/privateGPT/models/\n",
        "%cd /content/privateGPT/models/\n",
        "#!wget https://huggingface.co/TheBloke/koala-7B-GGML/resolve/main/koala-7B.ggmlv3.q4_0.bin\n",
        "!wget https://huggingface.co/gorborukov/koala-7b-ggml-q4_0/resolve/main/koala-7b-ggml-q4_0.bin"
      ],
      "metadata": {
        "id": "qypgc1qrvfX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%ls\n",
        "%ls models/"
      ],
      "metadata": {
        "id": "B2q6gGJv1ClM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title These were required before (for some filetypes), idk now\n",
        "!apt install pandoc\n",
        "!pip install unstructured"
      ],
      "metadata": {
        "id": "Gi4kGu_4zsjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Download documents\n",
        "%cd /content/localGPT\n",
        "%ls source_documents\n",
        "!curl https://ttx-download.oss-cn-hangzhou.aliyuncs.com/temp/%E5%86%B7%E7%9F%A5%E8%AF%86.txt -o source_documents/lengzhishi.txt"
      ],
      "metadata": {
        "id": "U3pVnaa2tIQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Ingest sources\n",
        "%cd /content/localGPT/\n",
        "!python3 ingest.py"
      ],
      "metadata": {
        "id": "UaNIO6crz2x3",
        "outputId": "e60ae300-eff6-48da-ea5d-a2d122abffab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/localGPT\n",
            "remote: Enumerating objects: 5, done.\u001b[K\n",
            "remote: Counting objects: 100% (5/5), done.\u001b[K\n",
            "remote: Compressing objects: 100% (1/1), done.\u001b[K\n",
            "remote: Total 3 (delta 2), reused 3 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (3/3), 275 bytes | 275.00 KiB/s, done.\n",
            "From https://github.com/alanland/localGPT\n",
            "   d5c5229..3058168  main-local -> origin/main-local\n",
            "Updating d5c5229..3058168\n",
            "Fast-forward\n",
            " run_localGPT_web.py | 2 \u001b[32m+\u001b[m\u001b[31m-\u001b[m\n",
            " 1 file changed, 1 insertion(+), 1 deletion(-)\n",
            "Loading documents from /content/localGPT/SOURCE_DOCUMENTS\n",
            "Loaded 1 documents from /content/localGPT/SOURCE_DOCUMENTS\n",
            "Split into 72 chunks of text\n",
            "load INSTRUCTOR_Transformer\n",
            "2023-06-05 15:16:50.693505: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Run the chatbot\n",
        "%cd /content/localGPT\n",
        "!git pull\n",
        "!python run_localGPT.py"
      ],
      "metadata": {
        "id": "mqa9t41jt1ZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Clear database\n",
        "!rm -rf /content/privateGPT/db"
      ],
      "metadata": {
        "id": "d2hePzFE0GK4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Zip the database if will reuse without recreating vectors\n",
        "!zip -r /content/db.zip /content/privateGPT/db"
      ],
      "metadata": {
        "id": "In4loHLa0IWy"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}