{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alanland/colab-notebooks/blob/main/wenda/wenda2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "du6mzCPzaZXb"
      },
      "outputs": [],
      "source": [
        "!nvidia-smi            # 查看GPU信息 #1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LLIbNMXfa7Ak"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "%ls"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EWOEdo-JHPJ4"
      },
      "source": [
        "# Clone Code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHYitAAkalZ6",
        "outputId": "c9c44ee4-38cc-472f-9a26-4035d8740668"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Error: Failed to call git rev-parse --git-dir: exit status 128 \n",
            "Git LFS initialized.\n",
            "Cloning into 'wenda'...\n",
            "remote: Enumerating objects: 2382, done.\u001b[K\n",
            "remote: Counting objects: 100% (595/595), done.\u001b[K\n",
            "remote: Compressing objects: 100% (127/127), done.\u001b[K\n",
            "remote: Total 2382 (delta 499), reused 468 (delta 468), pack-reused 1787\u001b[K\n",
            "Receiving objects: 100% (2382/2382), 19.29 MiB | 16.03 MiB/s, done.\n",
            "Resolving deltas: 100% (1444/1444), done.\n"
          ]
        }
      ],
      "source": [
        "!git lfs install \n",
        "%cd /content\n",
        "# !git clone https://github.com/l15y/wenda.git\n",
        "!git clone https://github.com/alanland/wenda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RRjuy7jLe-9w"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "# %rm chatglm-6b -rf \n",
        "#!git clone https://huggingface.co/THUDM/chatglm-6b #下载chatglm-6b模型\n",
        "!git clone https://huggingface.co/THUDM/chatglm-6b-int4 #轻量小内存的模型，感觉性能较差"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3S4wt2ejZoi"
      },
      "outputs": [],
      "source": [
        "%cd /content/wenda \n",
        "!pip install -r requirements.txt\n",
        "%pwd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0-EJzkRFRnk"
      },
      "source": [
        "# Ngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGaWeeu2FQGl"
      },
      "outputs": [],
      "source": [
        "!wget https://bin.equinox.io/c/bNyj1mQVY4c/ngrok-v3-stable-linux-amd64.tgz\n",
        "!tar zxvf ngrok-v3-stable-linux-amd64.tgz\n",
        "%ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XfT9zGcCF5Jt"
      },
      "outputs": [],
      "source": [
        "!mv ngrok /usr/local/bin/ \n",
        "!chmod +x /usr/local/bin/ngrok\n",
        "!ngrok --help"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xv7FBtpIGEm3"
      },
      "outputs": [],
      "source": [
        "!ngrok config add-authtoken 7PaC8UJ9ZPkUj6F3ubKH4_5r9ECx78ENWatsXJmTwE8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "juVhVFWgFVjb"
      },
      "source": [
        "# Cpolar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LEOlBCd4hbgG"
      },
      "outputs": [],
      "source": [
        "#@title cpolar install\n",
        "!wget https://static.cpolar.com/downloads/releases/3.3.18/cpolar-stable-linux-amd64.zip\n",
        "!unzip cpolar-stable-linux-amd64.zip "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ljTQE-4uh8jo"
      },
      "outputs": [],
      "source": [
        "!mv cpolar /usr/local/bin/ \n",
        "!chmod +x /usr/local/bin/cpolar\n",
        "!cpolar --help"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b0y9n0HFi_-s"
      },
      "outputs": [],
      "source": [
        "!cpolar authtoken YTIzOTg1MjEtZmNiNS00NTk2LTlhM2QtY2MxYTdkMjhhMTQ2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdcvnUcBFevN"
      },
      "source": [
        "# Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kIA7X-IGgn2Y",
        "outputId": "b4258eaf-e10a-4343-bfa7-76c8819f67e0"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/wenda\n",
            "remote: Enumerating objects: 9, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (5/5), done.\u001b[K\n",
            "remote: Total 9 (delta 4), reused 9 (delta 4), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (9/9), 5.51 KiB | 1.84 MiB/s, done.\n",
            "From https://github.com/alanland/wenda\n",
            "   418e93c..c63ac8c  main       -> origin/main\n",
            "Updating 418e93c..c63ac8c\n",
            "Fast-forward\n",
            " .gitignore |  1 \u001b[32m+\u001b[m\n",
            " wenda.py   | 11 \u001b[32m++++++\u001b[m\u001b[31m-----\u001b[m\n",
            " 2 files changed, 7 insertions(+), 5 deletions(-)\n",
            "Namespace(Config='config.xml', Port=None, Logging=None, LLM_Type='glm6b')\n",
            "\u001b[1;31m\u001b[1;31m\n",
            "\u001b[1;31m    Logging:\u001b[1;32m False\n",
            "\u001b[1;31m    Port:\u001b[1;32m 17860\n",
            "\u001b[1;31m    LLM_Type:\u001b[1;32m glm6b\n",
            "\u001b[1;31m    Path:\u001b[1;32m /content/chatglm-6b-int4\n",
            "\u001b[1;31m    Strategy:\u001b[1;32m cuda fp16i4\n",
            "\u001b[1;31m    Lora:\u001b[1;32m null\n",
            "\u001b[1;31m    library:\u001b[1;32m \u001b[1;31m\n",
            "\u001b[1;31m        Type:\u001b[1;32m mix\n",
            "\u001b[1;31m        Show_Soucre:\u001b[1;32m False\n",
            "\u001b[1;31m        Step:\u001b[1;32m 2\n",
            "\u001b[1;31m        mix:\u001b[1;32m \u001b[1;31m\n",
            "\u001b[1;31m            Strategy:\u001b[1;32m bing:\u001b[1;32m3 bingsite:\u001b[1;32m2 rtst:\u001b[1;32m2 agents:\u001b[1;32m0\n",
            "\u001b[1;31m            Count:\u001b[1;32m 5\n",
            "\u001b[1;31m        bing:\u001b[1;32m \u001b[1;31m\n",
            "\u001b[1;31m            Count:\u001b[1;32m 3\n",
            "\u001b[1;31m        bingsite:\u001b[1;32m \u001b[1;31m\n",
            "\u001b[1;31m            Count:\u001b[1;32m 2\n",
            "\u001b[1;31m            site:\u001b[1;32m www.12371.cn\n",
            "\u001b[1;31m        rtst:\u001b[1;32m \u001b[1;31m\n",
            "\u001b[1;31m            Count:\u001b[1;32m 2\n",
            "\u001b[1;31m            Model_Path:\u001b[1;32m GanymedeNil/text2vec-large-chinese\n",
            "\u001b[1;31m            Device:\u001b[1;32m cpu\n",
            "\u001b[1;31m        agents:\u001b[1;32m \u001b[1;31m\n",
            "\u001b[1;31m            Count:\u001b[1;32m 0\u001b[1;37m\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _ImportRedirect.find_spec() not found; falling back to find_module()\n",
            "serving on 0.0.0.0:17860 view at http://127.0.0.1:17860\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _ImportRedirect.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _ImportRedirect.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _ImportRedirect.find_spec() not found; falling back to find_module()\n",
            "/usr/local/lib/python3.10/dist-packages/tensorflow/__init__.py:29: DeprecationWarning: The distutils package is deprecated and slated for removal in Python 3.12. Use setuptools or check PEP 632 for potential alternatives\n",
            "  import distutils as _distutils\n",
            "2023-05-09 06:21:25.402013: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-05-09 06:21:27.708818: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _ImportRedirect.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _ImportRedirect.find_spec() not found; falling back to find_module()\n",
            "<frozen importlib._bootstrap>:914: ImportWarning: _ImportRedirect.find_spec() not found; falling back to find_module()\n",
            "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
            "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
            "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n",
            "/root/.cache/huggingface/modules/transformers_modules/local/modeling_chatglm.py:1259: DeprecationWarning: invalid escape sequence '\\?'\n",
            "  [\"\\?\", \"？\"],\n",
            "No sentence-transformers model found with name /root/.cache/torch/sentence_transformers/GanymedeNil_text2vec-large-chinese. Creating a new one with MEAN pooling.\n",
            "\u001b[1;32m知识库加载完成\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:121: DeprecationWarning: pkg_resources is deprecated as an API\n",
            "  warnings.warn(\"pkg_resources is deprecated as an API\", DeprecationWarning)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('paste')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.cloud')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:2349: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(parent)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('google.logging')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('mpl_toolkits')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "/usr/local/lib/python3.10/dist-packages/pkg_resources/__init__.py:2870: DeprecationWarning: Deprecated call to `pkg_resources.declare_namespace('sphinxcontrib')`.\n",
            "Implementing implicit namespace packages (as specified in PEP 420) is preferred to `pkg_resources.declare_namespace`. See https://setuptools.pypa.io/en/latest/references/keywords.html#keyword-namespace-packages\n",
            "  declare_namespace(pkg)\n",
            "\u001b[1;37mNo compiled kernel found.\n",
            "Compiling kernels : /root/.cache/huggingface/modules/transformers_modules/local/quantization_kernels.c\n",
            "Compiling gcc -O3 -fPIC -std=c99 /root/.cache/huggingface/modules/transformers_modules/local/quantization_kernels.c -shared -o /root/.cache/huggingface/modules/transformers_modules/local/quantization_kernels.so\n",
            "Load kernel : /root/.cache/huggingface/modules/transformers_modules/local/quantization_kernels.so\n",
            "Using quantization cache\n",
            "Applying quantization to glm layers\n",
            "\u001b[1;32m模型加载完成\n",
            "\u001b[1;37m\u001b[1;32m72.44.69.99:\u001b[1;31m时针从2指到6经过了多少小时\u001b[1;37m\n",
            "时针从2指到6指，需要经过12小时。 \n",
            "\n",
            "时针和分针的转动是相反的。时针每转动12圈，分针就会转动1圈。因此，时针从2指到6指的过程中，它转动了 12 ÷ 1 = 12 圈。也就是说，它在这段时间内从2指向6移动了12个刻度。\n",
            "\n",
            "此时，时针指向6，分针指向12。假设此时是12小时(小时数为整数)，那么在这12小时内，分针转动了 1 圈，时针转动了 12 圈，因此时针和分针指向的位置如下图所示：\n",
            "\n",
            "```\n",
            "    |\n",
            "    |\n",
            "    |\n",
            "    |\n",
            "    |\n",
            "    |\n",
            "    |\n",
            "    |\n",
            "    |\n",
            "    |\n",
            "    |\n",
            "    |\n",
            "    |\n",
            "    |\n",
            "    |\n",
            "    |\n",
            "    |\n",
            "    |\n",
            "    |\n",
            "    |\n",
            "    |\n",
            "    |\n",
            "    |\n",
            "    |\n",
            "```\n",
            "\n",
            "因此，时针从2指到6指经过12小时，也就是12小时。\n",
            "\u001b[1;32m72.44.69.99:\u001b[1;31m一个长方形的长5，宽度是3，它的周长是多少？\u001b[1;37m\n",
            "长方形的周长是其所有边的和，因此周长等于长加宽的两倍。\n",
            "\n",
            "长方形的长5，宽度3，则它的周长C=2(5+3)=13。\n",
            "\u001b[1;32m72.44.69.99:\u001b[1;31m那么它的面积呢？\u001b[1;37m\n",
            "抱歉，我需要更多的上下文信息才能回答您的问题。请提供更多详细信息，例如所在的城市或国家，以及相关的问题或陈述。\n",
            "\u001b[1;32m没有读取到RTST记忆区default，将新建。\n",
            "\u001b[1;37m'NoneType' object has no attribute 'embedding_function'\n",
            "\u001b[1;32m72.44.69.99:\u001b[1;31msystem: 请扮演一名专业分析师，根据以下内容回答问题：一个长方形的长5，宽度是3，它的周长是多少？\n",
            "\u001b[1;37m\n",
            "好的，这是一个基本的数学问题。长方形的周长是其所有边的和，因此周长等于长加宽的两倍。因此，这个长方形的周长为：\n",
            "\n",
            "C = 2(L + W)\n",
            "\n",
            "其中 L 是长方形的长度，W 是长方形的宽度。\n",
            "\n",
            "对于这个长方形，其长度为 5，宽度为 3，因此其周长为：\n",
            "\n",
            "C = 2(5 + 3) = 20\n",
            "\n",
            "因此，这个长方形的周长为 20 米。\n",
            "\u001b[1;32m没有读取到RTST记忆区default，将新建。\n",
            "\u001b[1;37m'NoneType' object has no attribute 'embedding_function'\n",
            "\u001b[1;32m72.44.69.99:\u001b[1;31msystem: 请扮演一名专业分析师，根据以下内容回答问题：那么它的面积呢？\n",
            "\u001b[1;37m\n",
            "非常抱歉，我需要更多的上下文信息才能回答您的问题。请提供更多详细信息，例如所在的城市或国家，以及相关的问题或陈述。\n"
          ]
        }
      ],
      "source": [
        "%cd /content/wenda\n",
        "!git pull\n",
        "#!cpolar http 17860 \n",
        "!export PYTHONIOENCODING=utf8\n",
        "!export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:32MB\n",
        "!python wenda.py -t glm6b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LWHnWyIpFiHv"
      },
      "source": [
        "# Debug"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGYtCzdrIhGP",
        "outputId": "f0f31e7c-e035-45ac-913b-05e5bf4a9907"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root        8686     482  0 10:22 ?        00:00:00 /bin/bash -c ps -fA | grep wenda\n",
            "root        8688    8686  0 10:22 ?        00:00:00 grep wenda\n"
          ]
        }
      ],
      "source": [
        "!ps -fA | grep wenda"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_vNTLz9NfEEt"
      },
      "outputs": [],
      "source": [
        "!cat setting.sh #看一下模型地址和模型参数 预量化的模型也直接跑fp16 #9 如果跑知识库这时候除了考这个setting.sh还要建zsk文件夹和考知识库文件进去\n",
        "!cat run_GLM6B.sh #不用看了\n",
        "#!sh setting.sh #不用执行\n",
        "\n",
        "!sh run_GLM6B.sh #不用执行\n",
        "# !wget -q https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64 -O /usr/bin/cloudflared && chmod +x /usr/bin/cloudflared #下载并授权网络映射 #10\n",
        "\n",
        "#!cloudflared --version #验证映射版本 #11 这个要看到版本说明装好\n",
        "#import os\n",
        "#os.environ['PATH'] += ':/usr/local/bin' #不用执行 "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMapU8rEbDV6pdrwhdr8tek",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}